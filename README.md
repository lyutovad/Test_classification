# Первый взгляд на данные.

* Классы

13 классов с сильным дисбалансом. Доля самого хорошо представленного класса 0.413104, минимально представленный класс всего 0.001859.
В дальнейшем, вероятно, можно попробовать сделать объединение самых малопредставленных классов с другими по смыслу (построить модель LDA, посмотреть распределение тематик, возможна ли перегруппировка)
Классы:
'COVID-19', 'Международные отношения', 'Россия', 'Социологические опросы', 'аналитика', 'военная тематика', 'инвестиция', 'меры поддержки', 'мнения', 'не по теме', 'политика', 'проекты', 'торговля'
* Очистка данных

Данные сильно зашумлены: смайлы, даты, ссылки на сайты и разные нерелевантные символы. 
Встречаются ссылки на источники данных, такие как РИА Новости 1 5 4.7 96б, ФГУП МИА «Россия сегодня» (не придумала, как быстро очистить данные от этой информации. Предполагаю, что Россия попадает  в частотность и из-за этих ссылок)
Также в данных встречаются дубли, причем строки могут быть абсолютно одинаковы по содержанию, но отличаться ссылками на источники, поэтому также ссылки на новостные каналы надо удалять и убирать дубли. От 4 повторов удалось избавиться после удаления ссылок на сайты.
Убрала ссылки, емейл-адреса, некоторые даты. метаинформацию с сайтов.
Т.к. темы относятся не к разговорной тематике, смайлы убрала. Убрала слова на латинице, т.к. они встретились в основном в названиях сайтов, изданий и т.п.
Оставила знак %, потому что посчитала, что он может быть показательным в таких темах как "аналитика" и "соцопросы", а также не стала убирать все числа, потому что-то они также могу указывать на статистику (вероятно, числа стоит убрать)
* Препроцессинг

Данные разбиты на токены, лемматизированы, очищены от стопслов (не проводила анализ на слова, которые стоит еще убрать. хотя, наверняка, найдется что-то ненужное).
Сформирован словарь из 2000 слов (надо проверить оптимальное количество). Максимальная длина 100, что нуждается в проверке (надо построить гистограмму распределения количества, обрезать правый хвост)
Классы переведены в метки. Данные преобразованы в вектора.

* Схема валидации

Данные разбиты на тренировочные и тестовые. Тест - 33%, пропорции классов при разделении данных соблюдены. При этом валидационная часть при обучении = 10%

* Метрика

Метрикой выбрана f1-score, потому что есть 13 классов. Смотрим взвешенные данные по классам
После предсказания выводится классификационный отчет

* Обучение модели

В первую очередь опробована модель с одним конволюционным слоем. f1 = 0.6182
Наименьшие классы вообще не определяются, точность на наиболее представленных классах 0,68-0,75
Сеть получается немного переобученная, надо делать регуляризацию, подбирать параметры.
Добавление в сеть слоя LSTM снизило скор.
Возможно, тут стоит подобрать архитектуру, порядок слоев. Есть ощущение, что рекуррентность может добавить к метрике.

* Что дальше

В целом по итогу такого первичного обучения видно, что надо поработать с дальнейшей очисткой данных. более глубоко изучить малочисленные классы.
Попробовать обученную трансформерную модель. Например, Roberta_Multiclass_TextClassification или аналоги.
